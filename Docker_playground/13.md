## ğŸ“ Project structure

```text
pytorch-training/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset/
â””â”€â”€ outputs/
    â”œâ”€â”€ checkpoints/
    â””â”€â”€ logs/
```

---

## ğŸ³ Dockerfile (GPU-enabled PyTorch)

```dockerfile
FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "train.py"]
```

---

## ğŸ“¦ requirements.txt

```text
torch
torchvision
numpy
tqdm
matplotlib
```

---

## ğŸ§© docker-compose.yml

version: "3.9"

services:
trainer:
container_name: pytorch_trainer
build: .
runtime: nvidia
environment:
- NVIDIA_VISIBLE_DEVICES=all
- NVIDIA_DRIVER_CAPABILITIES=compute,utility
- PYTHONUNBUFFERED=1
volumes:
- ./data:/app/data
- ./outputs:/app/outputs
command: >
python train.py
deploy:
resources:
reservations:
devices:
- driver: nvidia
count: all
capabilities: [gpu]
networks:
- ml_network

networks:
ml_network:
driver: bridge

---

## ğŸ§  train.py (example)

```python
import torch
from tqdm import tqdm

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

for epoch in range(5):
    for _ in tqdm(range(100)):
        pass

torch.save({"model": "dummy"}, "outputs/checkpoints/model.pt")
print("Training complete")
```

---

## ğŸš€ How to run

```bash
docker compose build
docker compose up
```

To stop:

```bash
docker compose down
```

---

## ğŸ” Why this setup is important (real-world ML projects)

### âœ… Dataset mounting

* Keeps **large datasets outside images**
* Easy swapping of datasets without rebuilding

### âœ… Output persistence

* Models, logs, checkpoints survive container restarts
* Essential for **experiments & versioning**

### âœ… GPU support

* Uses **NVIDIA Container Toolkit**
* Works with CUDA, cuDNN, multi-GPU systems

### âœ… Reproducibility

* Same environment for all team members
* No â€œworks on my machineâ€ problem

---

## âš ï¸ Prerequisites (VERY IMPORTANT)

You must install:

```bash
sudo apt install nvidia-container-toolkit
sudo systemctl restart docker
```

Verify GPU inside container:

```bash
docker run --rm --gpus all nvidia/cuda:11.8.0-base nvidia-smi
```
