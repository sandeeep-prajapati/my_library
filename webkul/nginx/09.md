## 1ï¸âƒ£ Architecture (What Weâ€™re Building)

```
Client
   â†“
 NGINX (Reverse Proxy)
   â”œâ”€â”€ /api/users  â†’ user-service (Node.js)
   â”œâ”€â”€ /api/orders â†’ order-service (Go/Django/etc)
   â””â”€â”€ /           â†’ frontend (React / static)
```

âœ” One public entry point
âœ” Services isolated
âœ” Easy scaling
âœ” Zero hardcoded IPs

---

## 2ï¸âƒ£ Folder Structure (Clean & Scalable)

```text
project-root/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ nginx/
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ user-service/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ order-service/
â”‚   â””â”€â”€ Dockerfile
```

---

## 3ï¸âƒ£ Microservice Dockerfiles

### ğŸŸ¦ User Service (Node.js example)

```dockerfile
# user-service/Dockerfile
FROM node:20-alpine

WORKDIR /app
COPY package*.json ./
RUN npm install --production
COPY . .

EXPOSE 3000
CMD ["node", "index.js"]
```

Runs on:

```
http://user-service:3000
```

---

### ğŸŸ© Order Service (Python / Django example)

```dockerfile
# order-service/Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .

EXPOSE 8000
CMD ["gunicorn", "app.wsgi:application", "--bind", "0.0.0.0:8000"]
```

---

### ğŸŸ¨ Frontend (React â€“ static build)

```dockerfile
# frontend/Dockerfile
FROM node:20-alpine AS build
WORKDIR /app
COPY . .
RUN npm install && npm run build

FROM nginx:alpine
COPY --from=build /app/build /usr/share/nginx/html
```

---

## 4ï¸âƒ£ Nginx Reverse Proxy Config (ğŸ”¥ Core)

```nginx
# nginx/nginx.conf
events {}

http {
    upstream user_service {
        server user-service:3000;
    }

    upstream order_service {
        server order-service:8000;
    }

    server {
        listen 80;

        # Frontend
        location / {
            root /usr/share/nginx/html;
            try_files $uri /index.html;
        }

        # User API
        location /api/users/ {
            proxy_pass http://user_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        # Order API
        location /api/orders/ {
            proxy_pass http://order_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}
```

âœ” Service discovery via **Docker DNS**
âœ” No IPs
âœ” Clean routing

---

## 5ï¸âƒ£ Docker Compose (Production-Ready)

```yaml
version: "3.9"

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./frontend/build:/usr/share/nginx/html:ro
    depends_on:
      - user-service
      - order-service
    restart: always

  user-service:
    build: ./user-service
    expose:
      - "3000"
    restart: always

  order-service:
    build: ./order-service
    expose:
      - "8000"
    restart: always
```

### Why `expose` instead of `ports`?

âœ” Internal-only services
âœ” More secure
âœ” Only Nginx is public

---

## 6ï¸âƒ£ Run It ğŸš€

```bash
docker compose build
docker compose up -d
```

Access:

* `http://localhost/` â†’ frontend
* `http://localhost/api/users`
* `http://localhost/api/orders`

---

## 7ï¸âƒ£ Production Hardening (VERY IMPORTANT)

### âœ… Health Checks

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
  interval: 30s
  timeout: 5s
  retries: 3
```

---

### âœ… Timeouts & Failover (Nginx)

```nginx
proxy_connect_timeout 5s;
proxy_read_timeout 30s;
proxy_next_upstream error timeout http_502 http_503;
```

---

### âœ… Scaling Services

```bash
docker compose up -d --scale user-service=3
```

Nginx will automatically load-balance ğŸ¯

---

## 8ï¸âƒ£ Common Production Pitfalls âš ï¸

âŒ Hardcoding `localhost` inside containers
âŒ Exposing all services publicly
âŒ No health checks
âŒ No restart policies
âŒ No request timeouts

---

## 9ï¸âƒ£ Why This Setup Is â€œProduction-Readyâ€

âœ” Single entry point
âœ” Isolated microservices
âœ” Built-in load balancing
âœ” Easy horizontal scaling
âœ” Secure networking
âœ” Docker-native DNS

---

## ğŸ¯ Interview-Ready Explanation (30 sec)

> â€œI use Nginx as a reverse proxy in Docker to route traffic to multiple microservices using service names for discovery. Only Nginx is exposed publicly, while backend services communicate internally. This setup supports load balancing, scaling, health checks, and clean API routing.â€

---
