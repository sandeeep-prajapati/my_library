# 1ï¸âƒ£ What is Nginx Load Balancing?

Nginx distributes incoming traffic across **multiple backend servers** to achieve:

* High availability
* Better performance
* Fault tolerance

```
Client
   â†“
 NGINX
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App-1   â”‚ App-2   â”‚ App-3   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 2ï¸âƒ£ Backend Pool (Upstream Block)

This is common for **all** strategies:

```nginx
upstream backend_pool {
    server 10.0.0.11:3000;
    server 10.0.0.12:3000;
    server 10.0.0.13:3000;
}
```

Then used via:

```nginx
proxy_pass http://backend_pool;
```

---

# 3ï¸âƒ£ Round-Robin (Default)

### Configuration

```nginx
upstream backend_pool {
    server 10.0.0.11:3000;
    server 10.0.0.12:3000;
    server 10.0.0.13:3000;
}
```

### How it works

* Requests are sent **sequentially**
* Equal distribution
* No state awareness

### Real-World Use Case

âœ” Stateless REST APIs
âœ” Microservices
âœ” Public APIs
âœ” When all servers have **similar capacity**

### Example

```
Req1 â†’ App1
Req2 â†’ App2
Req3 â†’ App3
Req4 â†’ App1
```

âš ï¸ Not ideal if:

* Some requests are heavier than others

---

# 4ï¸âƒ£ Least Connections

### Configuration

```nginx
upstream backend_pool {
    least_conn;

    server 10.0.0.11:3000;
    server 10.0.0.12:3000;
    server 10.0.0.13:3000;
}
```

### How it works

* Sends traffic to server with **fewest active connections**
* Dynamic balancing

### Real-World Use Case

âœ” Long-running requests
âœ” File uploads / downloads
âœ” ML / report generation APIs
âœ” WebSocket-heavy apps

### Example

```
App1 â†’ 10 active connections
App2 â†’ 3 active connections  â† new request goes here
App3 â†’ 7 active connections
```

âš ï¸ Slightly more overhead than round-robin

---

# 5ï¸âƒ£ IP Hash (Session Persistence)

### Configuration

```nginx
upstream backend_pool {
    ip_hash;

    server 10.0.0.11:3000;
    server 10.0.0.12:3000;
    server 10.0.0.13:3000;
}
```

### How it works

* Client IP â†’ hashed â†’ same backend every time
* Ensures **sticky sessions**

### Real-World Use Case

âœ” Legacy apps using in-memory sessions
âœ” Shopping carts
âœ” Auth without shared cache
âœ” WebSocket session affinity

### Example

```
User A (IP X) â†’ App2 (always)
User B (IP Y) â†’ App1 (always)
```

âš ï¸ Problems

* Bad with NAT / mobile networks
* Uneven traffic distribution

---

# 6ï¸âƒ£ Complete Nginx Load Balancer Config

```nginx
server {
    listen 80;

    location / {
        proxy_pass http://backend_pool;

        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 5s;
        proxy_read_timeout 60s;
    }
}
```

---

# 7ï¸âƒ£ Health Checks (Basic)

```nginx
upstream backend_pool {
    server 10.0.0.11:3000 max_fails=3 fail_timeout=30s;
    server 10.0.0.12:3000 max_fails=3 fail_timeout=30s;
}
```

If a server fails:
â¡ Nginx temporarily removes it

---

# 8ï¸âƒ£ Strategy Comparison (Quick Table)

| Strategy          | Best For        | Not Good For          |
| ----------------- | --------------- | --------------------- |
| Round-robin       | Stateless APIs  | Heavy uneven loads    |
| Least connections | Long requests   | CPU-bound short tasks |
| IP hash           | Sticky sessions | Mobile users, NAT     |

---

# 9ï¸âƒ£ Pro Tips (Production)

âœ” Prefer **stateless apps + Redis sessions**
âœ” Use **round-robin** whenever possible
âœ” Avoid IP hash unless absolutely needed
âœ” For WebSockets â†’ least_conn + sticky logic
âœ” Always combine with **timeouts + retries**

---

# ğŸ”Ÿ Interview-Ready 30-Second Answer

> â€œNginx supports round-robin, least connections, and IP hash load balancing. Round-robin is best for stateless APIs, least connections for long-lived requests, and IP hash for session persistence. Nginx efficiently distributes traffic using event-driven workers with minimal memory overhead.â€

