# 1ï¸âƒ£ Worker Process & Event Tuning (Foundation)

### CPU-aware workers

```nginx
worker_processes auto;
```

### Max connections per worker

```nginx
events {
    worker_connections 65535;
    use epoll;
    multi_accept on;
}
```

**Why it matters**

* One worker = one CPU core
* Event-driven â†’ minimal context switching
* `multi_accept` accepts multiple connections at once

---

# 2ï¸âƒ£ Open File Limits (CRITICAL for High Traffic)

```nginx
worker_rlimit_nofile 100000;
```

Also update OS limits:

```bash
ulimit -n
```

ğŸ‘‰ Without this, Nginx silently throttles

---

# 3ï¸âƒ£ Keep-Alive (Reduce TCP Overhead)

```nginx
http {
    keepalive_timeout 65;
    keepalive_requests 10000;
}
```

### Upstream keepalive

```nginx
upstream backend {
    server 127.0.0.1:3000;
    keepalive 64;
}
```

**Benefit**

* Fewer TCP handshakes
* Faster API responses
* Lower backend load

---

# 4ï¸âƒ£ Gzip Compression (Must-Have)

```nginx
gzip on;
gzip_comp_level 6;
gzip_min_length 1024;
gzip_vary on;
gzip_proxied any;

gzip_types
    text/plain
    text/css
    application/json
    application/javascript
    text/xml
    application/xml
    image/svg+xml;
```

### Result

* 60â€“80% size reduction
* Faster page loads
* Lower bandwidth costs

âš ï¸ Donâ€™t gzip already-compressed files (jpg, png, zip)

---

# 5ï¸âƒ£ Brotli Compression (Even Better ğŸš€)

> Brotli > Gzip (modern browsers)

### Enable (requires module)

```nginx
brotli on;
brotli_comp_level 6;
brotli_static on;

brotli_types
    text/plain
    text/css
    application/json
    application/javascript
    text/xml
    application/xml
    image/svg+xml;
```

**Pro Tip**

* Use **Brotli + Gzip fallback**
* Brotli for HTTPS traffic

---

# 6ï¸âƒ£ Sendfile & TCP Optimizations

```nginx
sendfile on;
tcp_nopush on;
tcp_nodelay on;
```

### Why

* `sendfile` â†’ zero-copy file transfer
* `tcp_nopush` â†’ efficient packet batching
* `tcp_nodelay` â†’ low latency

Perfect for:
âœ” Static assets
âœ” Downloads
âœ” Media files

---

# 7ï¸âƒ£ Static File Caching (Browser + Proxy Cache)

### Browser Cache

```nginx
location ~* \.(css|js|jpg|jpeg|png|gif|ico|svg|woff2)$ {
    expires 30d;
    add_header Cache-Control "public, immutable";
}
```

### Nginx Proxy Cache

```nginx
proxy_cache_path /var/cache/nginx
    levels=1:2
    keys_zone=STATIC:100m
    max_size=10g
    inactive=60m
    use_temp_path=off;
```

```nginx
location / {
    proxy_cache STATIC;
    proxy_cache_valid 200 301 302 10m;
    proxy_cache_use_stale error timeout updating;

    proxy_pass http://backend;
}
```

**Result**

* Massive backend offload
* Sub-millisecond responses

---

# 8ï¸âƒ£ Buffer Tuning (Prevent 502 / Slow Clients)

```nginx
client_body_buffer_size 128k;
client_header_buffer_size 1k;
large_client_header_buffers 4 8k;

proxy_buffers 16 16k;
proxy_buffer_size 32k;
```

Stops:

* Header overflow errors
* Slow client blocking

---

# 9ï¸âƒ£ Logging Optimization (Often Ignored)

High traffic + heavy logs = I/O bottleneck

```nginx
access_log off;
```

Or sample logs:

```nginx
access_log /var/log/nginx/access.log combined buffer=512k flush=1m;
```

---

# ğŸ”Ÿ Full High-Traffic HTTP Block (Safe Defaults)

```nginx
http {
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;

    keepalive_timeout 65;
    keepalive_requests 10000;

    gzip on;
    gzip_comp_level 6;

    worker_rlimit_nofile 100000;
}
```

---

# 11ï¸âƒ£ Real-World Performance Impact

| Optimization    | Impact                         |
| --------------- | ------------------------------ |
| Workers + epoll | 10x concurrency                |
| Keep-alive      | 30â€“50% latency drop            |
| Gzip/Brotli     | 60â€“80% size reduction          |
| Proxy cache     | 80% backend offload            |
| Sendfile        | Near-zero CPU for static files |

---

# 12ï¸âƒ£ Common Mistakes (âš ï¸ Avoid These)

âŒ Too many workers â†’ CPU thrashing
âŒ Gzip level too high â†’ CPU burn
âŒ Cache dynamic auth responses
âŒ Forget OS limits
âŒ Disable logs blindly (debug pain)

---

# ğŸ¯ Interview-Ready Answer (30 sec)

> â€œI optimize Nginx by tuning worker processes with epoll, enabling keep-alive, using gzip and Brotli compression, serving static files via sendfile, adding browser and proxy caching, and increasing OS file limits for high concurrency.â€

