Here’s a step-by-step guide to extract a **512-dimensional feature vector** from a user-uploaded image using a PyTorch model (e.g., ResNet18 or a custom encoder). We’ll use a pre-trained model and modify it to return embeddings instead of classification scores.

---

### **Step 1: Install Required Libraries**
```bash
pip install torch torchvision pillow numpy
```

---

### **Step 2: Load Pre-trained Model and Modify for Embeddings**
We’ll use **ResNet18** (which outputs 512-d vectors when the final layer is removed) or a custom model like **`torchvision.models.resnet18`**.

```python
import torch
import torchvision.models as models
from torchvision import transforms
from PIL import Image

# Load pre-trained ResNet18 (outputs 512-d embeddings after avgpool)
model = models.resnet18(pretrained=True)

# Remove the final fully connected layer (keep avgpool)
model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Output: [batch, 512, 1, 1]

# Set to evaluation mode
model.eval()

# Move to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
```

---

### **Step 3: Preprocess the User-Uploaded Image**
```python
def preprocess_image(image_path):
    # Define transformations (must match model's training preprocessing)
    transform = transforms.Compose([
        transforms.Resize(256),             # Resize to 256x256
        transforms.CenterCrop(224),         # Crop center 224x224
        transforms.ToTensor(),              # Convert to tensor
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],     # ImageNet normalization
            std=[0.229, 0.224, 0.225]
        ),
    ])
    
    # Load image and apply transformations
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0)  # Add batch dimension
    return image.to(device)

# Example usage
image_path = "user_uploaded_image.jpg"
input_tensor = preprocess_image(image_path)
```

---

### **Step 4: Extract the 512-Dimensional Embedding**
```python
def extract_embedding(input_tensor):
    with torch.no_grad():  # Disable gradient calculation
        embedding = model(input_tensor)      # Shape: [1, 512, 1, 1]
        embedding = embedding.squeeze()      # Remove extra dims -> [512]
    return embedding.cpu().numpy()           # Convert to numpy array

# Get the embedding vector
embedding = extract_embedding(input_tensor)
print("Embedding shape:", embedding.shape)   # (512,)
print("First 5 values:", embedding[:5])      # Example output
```

---

### **Step 5: Save or Use the Embedding**
```python
import numpy as np

# Save to disk
np.save("image_embedding.npy", embedding)

# Or use it for similarity search (e.g., with Qdrant/FAISS)
# Example: Compare with other embeddings using cosine similarity
from sklearn.metrics.pairwise import cosine_similarity

# Assume `database_embeddings` is a matrix of shape [N, 512]
similarity_scores = cosine_similarity(embedding.reshape(1, -1), database_embeddings)
print("Similarity scores:", similarity_scores)
```

---

### **Alternative: Use a Custom Model (e.g., for 512-d Output)**
If you need exactly **512-d** (e.g., for compatibility with a specific system), you can:
1. **Add a projection layer** to ResNet:
   ```python
   model = models.resnet18(pretrained=True)
   model.fc = torch.nn.Linear(512, 512)  # Force 512-d output
   ```
2. **Use a smaller model** (e.g., `ResNet34` or `MobileNetV3` with adaptation).

---

### **Key Notes**
1. **Model Choice**:  
   - `ResNet18`: 512-d (after removing `fc`).  
   - `ResNet50`: 2048-d (use PCA to reduce to 512-d if needed).  
   - `MobileNetV3`: Smaller embeddings (adjust final layer).

2. **Preprocessing**:  
   Always use the same normalization (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`) as the pretrained model.

3. **GPU vs CPU**:  
   For faster inference, use `model.to("cuda")`.

4. **Batch Processing**:  
   For multiple images, stack tensors:
   ```python
   batch = torch.cat([preprocess_image(img) for img in image_paths])
   embeddings = extract_embedding(batch)  # Shape: [N, 512]
   ```

---

### **Example Output**
```python
Embedding shape: (512,)
First 5 values: [0.12, -0.45, 0.87, 0.23, -0.56]
```
