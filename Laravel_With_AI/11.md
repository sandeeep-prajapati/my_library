
---

### **1. Basic Setup (`main.py`)**
```python
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from pydantic import BaseModel
from typing import List, Union
import torch
from PIL import Image
import io

app = FastAPI(title="Embedding Service")

# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["POST"],
)

# --- Model Loading ---
model = None  # Placeholder for your actual model

def load_models():
    """Initialize models on startup"""
    global model
    # Example: Load pretrained ResNet50
    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)
    model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove last layer
    model.eval()

@app.on_event("startup")
async def startup_event():
    load_models()

# --- Request Models ---
class TextRequest(BaseModel):
    texts: List[str]

class ImageBatchRequest(BaseModel):
    image_urls: List[str]  # Or base64 encoded images

@app.post("/embed")
async def embed_data(
    texts: Union[TextRequest, None] = None,
    images: List[UploadFile] = None
):
    """Handle both text and image embedding requests"""
    try:
        if texts:
            return handle_text_embedding(texts)
        elif images:
            return handle_image_embedding(images)
        else:
            raise HTTPException(status_code=400, detail="No valid input provided")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- Core Processing Functions ---
def handle_text_embedding(request: TextRequest):
    """Convert texts to embeddings"""
    # Replace with your actual text model (e.g., Sentence-BERT)
    embeddings = []
    for text in request.texts:
        # Dummy implementation - replace with real model
        embedding = np.random.rand(512).tolist()  # Simulate 512-dim vector
        embeddings.append(embedding)
    
    return {"embeddings": embeddings}

def handle_image_embedding(files: List[UploadFile]):
    """Process batch of images"""
    embeddings = []
    for file in files:
        try:
            contents = await file.read()
            img = Image.open(io.BytesIO(contents)).convert("RGB")
            embedding = image_to_embedding(img)
            embeddings.append(embedding.tolist())
        except Exception as e:
            raise HTTPException(
                status_code=422, 
                detail=f"Failed to process {file.filename}: {str(e)}"
            )
    
    return {"embeddings": embeddings}

def image_to_embedding(img: Image.Image) -> np.ndarray:
    """Convert PIL image to embedding"""
    # Preprocessing
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        ),
    ])
    
    img_tensor = transform(img).unsqueeze(0)
    
    # Inference
    with torch.no_grad():
        embedding = model(img_tensor).squeeze().numpy()
    
    return embedding

# --- Health Check ---
@app.get("/health")
async def health_check():
    return {"status": "healthy", "model_loaded": model is not None}
```

---

### **2. Dockerfile**
```dockerfile
FROM python:3.9-slim

WORKDIR /app

RUN pip install torch torchvision pillow fastapi uvicorn numpy python-multipart

COPY main.py .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

---

### **3. Test with cURL**

#### **Text Embedding**
```bash
curl -X POST http://localhost:8000/embed \
  -H "Content-Type: application/json" \
  -d '{"texts": ["hello world", "machine learning"]}'
```

#### **Image Embedding**
```bash
curl -X POST http://localhost:8000/embed \
  -F "images=@cat.jpg" \
  -F "images=@dog.jpg"
```

---

### **4. Key Features**

1. **Multi-Input Support**:
   - Text strings
   - Image uploads (batch processing)
   - Hybrid inputs (extendable)

2. **Production-Ready**:
   - Async I/O for file uploads
   - Proper error handling
   - CORS configured
   - Health check endpoint

3. **Performance Optimizations**:
   - Model pre-loading on startup
   - Batch processing support
   - GPU-ready (add `torch.cuda` if available)

4. **Response Format**:
```json
{
  "embeddings": [
    [0.12, -0.34, ..., 0.98],  // Vector 1
    [0.23, 0.45, ..., -0.67]   // Vector 2
  ]
}
```

---

### **5. Advanced Extensions**

#### **Add Authentication**
```python
from fastapi.security import APIKeyHeader

api_key_header = APIKeyHeader(name="X-API-Key")

@app.post("/secure-embed")
async def secure_embed(
    api_key: str = Depends(api_key_header),
    texts: TextRequest = None
):
    if api_key != "your-secret-key":
        raise HTTPException(status_code=401, detail="Invalid API key")
    return await embed_data(texts)
```

#### **Add Rate Limiting**
```python
from fastapi import Request
from fastapi.middleware import Middleware
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/limited-embed")
@limiter.limit("10/minute")
async def limited_embed(request: Request, texts: TextRequest):
    return handle_text_embedding(texts)
```

---

### **6. Deployment**

#### **With Gunicorn (Production)**
```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker main:app
```

#### **Docker Compose**
```yaml
services:
  embedding-service:
    build: .
    ports:
      - "8000:8000"
    environment:
      - WORKERS_PER_CORE=2
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
```

---
