Hereâ€™s how to **store image/text embeddings in Qdrant** using both the **Python client** and **HTTP API**, with a focus on `upload_collection()` for batch insertion:

---

### **1. Python Client (Recommended)**
#### **Install the Client**
```bash
pip install qdrant-client numpy
```

#### **Step-by-Step Code**
```python
from qdrant_client import QdrantClient
from qdrant_client.http import models
import numpy as np

# Initialize client (local or cloud)
client = QdrantClient(host="localhost", port=6333)  # For Qdrant Cloud: `url="https://xxx-xxx-xxx.cloud.qdrant.io"`

# Create a collection (if not exists)
client.recreate_collection(
    collection_name="image_embeddings",
    vectors_config=models.VectorParams(
        size=512,  # Dimension of your embeddings (e.g., 512 for ResNet18)
        distance=models.Distance.COSINE  # Similarity metric
    )
)

# Generate dummy embeddings (replace with your actual data)
embeddings = np.random.rand(100, 512).tolist()  # 100 vectors of 512-dim
payloads = [{"image_id": f"img_{i}", "label": "cat" if i % 2 == 0 else "dog"} for i in range(100)]

# Batch upload using upload_collection (fastest method)
client.upload_collection(
    collection_name="image_embeddings",
    vectors=embeddings,
    payload=payloads,          # Optional metadata
    ids=None,                  # Auto-generate IDs if None
    batch_size=256             # Optimize based on your RAM
)

print("Embeddings uploaded successfully!")
```

#### **Key Parameters for `upload_collection()`**
| Parameter      | Description                                                                 |
|----------------|-----------------------------------------------------------------------------|
| `vectors`      | List of embeddings (e.g., `[[0.1, 0.2, ...], ...]`).                       |
| `payload`      | Optional metadata per vector (e.g., `[{"image_id": "img1"}, ...]`).         |
| `ids`          | Custom IDs (e.g., `[1, 2, 3]`). If `None`, auto-generates sequential IDs.   |
| `batch_size`   | Number of vectors per batch (default: `256`). Reduce if memory-limited.     |

---

### **2. HTTP API (curl)**
#### **Create Collection**
```bash
curl -X PUT http://localhost:6333/collections/text_embeddings \
  -H 'Content-Type: application/json' \
  -d '{
    "vectors": {
      "size": 768,          # e.g., for BERT embeddings
      "distance": "Cosine"
    }
  }'
```

#### **Batch Insert Vectors**
```bash
curl -X POST http://localhost:6333/collections/text_embeddings/points \
  -H 'Content-Type: application/json' \
  -d '{
    "points": [
      {
        "id": 1,
        "vector": [0.1, 0.2, ..., 0.768],
        "payload": {"text_id": "doc_1", "source": "wikipedia"}
      },
      {
        "id": 2,
        "vector": [0.3, 0.5, ..., 0.768],
        "payload": {"text_id": "doc_2", "source": "news"}
      }
    ]
  }'
```

---

### **3. Verify Insertion**
#### **Python**
```python
# Check collection info
collection_info = client.get_collection("image_embeddings")
print(f"Total vectors: {collection_info.vectors_count}")

# Search for similar vectors
hits = client.search(
    collection_name="image_embeddings",
    query_vector=[0.1] * 512,  # Example query
    limit=3
)
for hit in hits:
    print(f"ID: {hit.id}, Score: {hit.score}, Payload: {hit.payload}")
```

#### **HTTP API**
```bash
curl http://localhost:6333/collections/image_embeddings/points/count
```

---

### **4. Advanced Options**
#### **Custom IDs and Parallel Uploads**
```python
from qdrant_client.models import PointStruct

# Manually specify IDs and use parallel uploads
points = [
    PointStruct(
        id=i, 
        vector=emb, 
        payload={"image_id": f"img_{i}"}
    )
    for i, emb in enumerate(embeddings)
]

client.upsert(
    collection_name="image_embeddings",
    points=points,
    wait=True  # Wait until all points are processed
)
```

#### **Large-Scale Uploads**
For **millions of vectors**, use:
- **Batch processing** (smaller `batch_size`).
- **Async uploads** (`wait=False`).
- **Parallel HTTP requests** (if using API directly).

---

### **Key Notes**
1. **Performance Tips**:
   - Use `upload_collection()` for fastest batch inserts.
   - For **GPU-generated embeddings**, transfer data to CPU first (`embeddings.cpu().numpy()`).

2. **Payloads**:
   - Attach metadata (e.g., `image_id`, `text`) for filtering later.

3. **Distance Metrics**:
   - `COSINE`: Best for normalized embeddings.
   - `EUCLIDEAN`: For L2-normalized vectors.

4. **Qdrant Cloud**:
   - Replace `localhost` with your cloud instance URL and add API key:
     ```python
     client = QdrantClient(
         url="https://xxx.cloud.qdrant.io",
         api_key="your-api-key"
     )
     ```

---
